import sys
import os
import json
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# Imports do Projeto
from src.config import RAW_DIR, VECTOR_DB_DIR
from src.ingestion.pdf_loader import processar_documento
from src.ingestion.table_summarizer import gerar_resumos_tabelas
from src.models.rag_engine import RAGEngine
from src.models.llm_factory import LLMFactory
from src.prompts.templates import PROMPT_RAG_FINAL, PROMPT_EXTRACAO
from src.evaluation.hallucination_check import VerificadorAlucinacao
from src.evaluation.saver import configurar_logger, salvar_relacoes_csv

# Inicializa o Logger Global
logger = configurar_logger()


def verificar_arquivo_entrada():
    """Verifica se existe PDF na pasta raw."""
    arquivos = list(RAW_DIR.glob("*.pdf"))
    if not arquivos:
        logger.error(f"Nenhum PDF encontrado em {RAW_DIR}")
        sys.exit(1)
    return arquivos[0].name


def pipeline_ingestao(nome_arquivo):
    logger.info(f"üöÄ INICIANDO INGEST√ÉO: {nome_arquivo}")

    # 1. Extra√ß√£o
    logger.info("--- [Etapa 1.1] Extra√ß√£o Texto/Tabela ---")
    processar_documento(nome_arquivo)

    # 2. Resumo
    logger.info("--- [Etapa 1.2] Gera√ß√£o de Resumos ---")
    gerar_resumos_tabelas()

    # 3. Indexa√ß√£o
    logger.info("--- [Etapa 2.1] Indexa√ß√£o Vetorial ---")
    motor = RAGEngine()
    motor.indexar_dados()

    logger.info("‚úÖ Ingest√£o conclu√≠da!")


def pipeline_chat():
    logger.info("ü§ñ SISTEMA ECLADATTA - INICIADO")

    # Carrega Motor
    motor = RAGEngine()
    retriever = motor.get_retriever()
    llm = LLMFactory.create_chat_model(temperature=0)
    verificador = VerificadorAlucinacao()

    # Cadeia de Chat (Conversa)
    rag_chain = (
            {"context": retriever, "question": RunnablePassthrough()}
            | PROMPT_RAG_FINAL
            | llm
            | StrOutputParser()
    )

    # Cadeia de Extra√ß√£o (Para popular o CSV)
    # Usa o prompt espec√≠fico 'extracao_relacoes' do seu YAML
    extraction_chain = (
            PROMPT_EXTRACAO
            | llm
            | StrOutputParser()
    )

    print("\n--- ECLADATTA PRONTO ---")
    print("Digite 'sair' para encerrar.")
    print("Digite 'extrair' para for√ßar a extra√ß√£o de rela√ß√µes do √∫ltimo contexto.")

    ultimo_contexto = ""

    while True:
        pergunta = input("\nüë§ Voc√™: ")
        if pergunta.lower() in ['sair', 'exit']:
            break

        # Op√ß√£o manual para salvar no CSV (ou poderia ser autom√°tico)
        if pergunta.lower() == 'extrair':
            if not ultimo_contexto:
                print("‚ö†Ô∏è Fa√ßa uma pergunta primeiro para carregar o contexto.")
                continue

            print("‚è≥ Extraindo rela√ß√µes estruturadas para CSV...")
            try:
                # Chama o LLM pedindo JSON
                json_resultado = extraction_chain.invoke({
                    "texto_input": ultimo_contexto,
                    "tabela_input": "Verificar contexto acima"
                })
                # Salva no arquivo
                salvar_relacoes_csv(json_resultado, fonte="interacao_usuario")
            except Exception as e:
                logger.error(f"Erro na extra√ß√£o: {e}")
            continue

        # Fluxo Normal de Chat
        logger.info(f"Pergunta recebida: {pergunta}")
        print("‚è≥ Processando...", end="\r")

        # 1. Recupera Contexto
        docs = retriever.invoke(pergunta)
        contexto_str = "\n".join([d.page_content for d in docs])
        ultimo_contexto = contexto_str  # Guarda para uso na extra√ß√£o

        # 2. Gera Resposta
        resposta = rag_chain.invoke(pergunta)

        # 3. Valida Alucina√ß√£o
        analise = verificador.verificar_consistencia_numerica(resposta, contexto_str)

        print(f"\nü§ñ ECLADATTA: {resposta}")

        if analise.get("tem_alucinacao"):
            logger.warning(f"Alucina√ß√£o detectada: {analise}")
            print(f"\n‚ö†Ô∏è ALERTA: Poss√≠vel inconsist√™ncia num√©rica.")

        # Opcional: Extra√ß√£o Autom√°tica (Se quiser popular o CSV sempre)
        # salvar_relacoes_csv(extraction_chain.invoke({...}), fonte="auto")


def main():
    if not os.path.exists(VECTOR_DB_DIR):
        print("Banco de dados n√£o encontrado. Iniciando ingest√£o...")
        arquivo = verificar_arquivo_entrada()
        pipeline_ingestao(arquivo)

    # Menu simples
    print("1. Re-processar documentos")
    print("2. Iniciar Chat")
    escolha = input("Op√ß√£o: ").strip()

    if escolha == "1":
        arquivo = verificar_arquivo_entrada()
        pipeline_ingestao(arquivo)
        pipeline_chat()
    else:
        pipeline_chat()


if __name__ == "__main__":
    main()